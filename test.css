import re
import json
import time
import logging
import base64
import hmac
import hashlib
import requests
from typing import Dict, List, Optional, Tuple
from google.oauth2 import service_account
from google.auth.transport.requests import Request

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AIController:
    def __init__(self):
        # Import constants
        from constants import (
            APPID,
            SECRET,
            VERSION,
            IDAAS_URL,
            LLM_URL,
            EMBEDDINGS_URL,
            DB_HOST,
            DB_PORT,
            DB_NAME,
            DB_USER,
            DB_PASSWORD
        )
        
        # Set constants from imports
        self.APPID = APPID
        self.SECRET = SECRET
        self.VERSION = VERSION
        self.IDAAS_URL = IDAAS_URL
        self.LLM_URL = LLM_URL
        self.EMBEDDINGS_URL = EMBEDDINGS_URL
        
        # Set constants from imports
        self.APPID = APPID
        self.SECRET = SECRET
        self.VERSION = VERSION
        self.IDAAS_URL = IDAAS_URL
        self.LLM_URL = LLM_URL
        self.EMBEDDINGS_URL = EMBEDDINGS_URL
        
        # Vector DB configuration from constants
        self.vector_db_config = {
            "host": DB_HOST,
            "port": DB_PORT,
            "database": DB_NAME,
            "user": DB_USER,
            "password": DB_PASSWORD
        }

    def scan_pii(self, text: str) -> Dict[str, List[str]]:
        """
        Scan text for PII such as SSN, email, phone numbers
        """
        pii_findings = {
            'ssn': [],
            'email': [],
            'phone': [],
            'credit_card': []
        }
        
        patterns = {
            'ssn': r'\b\d{3}-\d{2}-\d{4}\b',
            'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
            'phone': r'\b(\+\d{1,2}\s?)?\(?\d{3}\)?[\s.-]?\d{3}[\s.-]?\d{4}\b',
            'credit_card': r'\b\d{4}[- ]?\d{4}[- ]?\d{4}[- ]?\d{4}\b'
        }
        
        for pii_type, pattern in patterns.items():
            matches = re.findall(pattern, text)
            if matches:
                pii_findings[pii_type].extend(matches)
        
        return pii_findings

    def get_gcp_token(self):
        """
        Generates the GCP token using the SERVICE_ACCOUNT_FILE
        The token is used to authenticate the user to the GCP service
        """
        try:
            # Import required
            from google.oauth2 import service_account
            from google.auth.transport.requests import Request
            from constants import SERVICE_ACCOUNT_FILE

            # Set up authentication scopes
            SCOPES = ["https://www.googleapis.com/auth/cloud-platform"]
            
            # Load the credentials file
            credentials = service_account.Credentials.from_service_account_file(
                SERVICE_ACCOUNT_FILE, scopes=SCOPES)
            
            # Get and refresh the token
            gcp_auth_request = google.auth.transport.requests.Request()
            credentials.refresh(gcp_auth_request)
            return credentials.token
            
        except Exception as e:
            logger.error(f"Error getting GCP token: {str(e)}")
            raise

    def get_idaas_auth_token(self):
        """
        Generates the IDaaS token using the APPID, SECRET, VERSION and IDAAS_URL
        The token is used to authenticate the user to the IDaaS service
        """
        try:
            # Create HMAC signature
            mac = hmac.new(base64.b64decode(self.SECRET), digestmod=hashlib.sha256)
            timestamp = str(int(time.time() * 1000))
            
            # Format input data
            input_data = "{}.{}.{}".format(self.APPID.strip(), self.VERSION, timestamp)
            mac.update(input_data.encode('utf-8'))
            
            # Generate and format signature
            hmac_signature = base64.urlsafe_b64encode(mac.digest()).decode('utf-8')
            hmac_signature = hmac_signature.replace("/", "_").replace("+", "-").replace("=", "")
            
            # Create IDaaS headers
            idaas_headers = {
                'Content-Type': 'application/json',
                'X-Auth-AppID': self.APPID,
                'X-Auth-Signature': hmac_signature,
                'X-Auth-Version': self.VERSION,
                'X-Auth-Timestamp': timestamp,
                'Accept': 'application/json'
            }
            
            return idaas_headers
            
        except Exception as e:
            logger.error(f"Error generating IDaaS token: {str(e)}")
            raise

    def get_embeddings(self, text: str) -> List[float]:
        """
        Generate embeddings using the bge-large model
        """
        try:
            # Get IDAAS token first
            idaas_token = self.get_idaas_auth_token()
            
            headers = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {idaas_token}',
                'Accept': 'application/json'
            }
            
            embeddings_payload = {
                "instances": [
                    {"input": text}
                ]
            }
            
            logger.info(f"Payload: {embeddings_payload}")
            
            response = requests.post(
                self.EMBEDDINGS_URL,
                headers=headers,
                data=json.dumps(embeddings_payload),
                verify=False  # Note: In production, use proper certificate verification
            )
            
            if response.status_code == 200:
                return response.json()['embeddings'][0]
            else:
                logger.error(f"Embedding API error: {response.status_code}, {response.text}")
                raise Exception(f"Embedding API error: {response.text}")
                
        except Exception as e:
            logger.error(f"Error generating embeddings: {str(e)}")
            raise

    def semantic_search(
        self, 
        embedding: List[float], 
        limit: int = 3,
        similarity_threshold: float = 0.7
    ) -> List[Dict]:
        """
        Perform semantic search in vector database
        """
        try:
            # Here you would implement your vector database search
            # This is a placeholder - implement based on your chosen vector DB
            query = f"""
                SELECT text, embedding_vector, 
                       1 - (embedding_vector <=> '{embedding}') as similarity
                FROM documents
                WHERE 1 - (embedding_vector <=> '{embedding}') > {similarity_threshold}
                ORDER BY similarity DESC
                LIMIT {limit}
            """
            
            # Execute query and return results
            # Placeholder return
            return [{"text": "Sample context", "similarity": 0.85}]
            
        except Exception as e:
            logger.error(f"Error in semantic search: {str(e)}")
            raise

    def call_llm(self):
        """
        Call LLM - Gemini
        This method calls the LLM service using the IDaaS token and GCP token
        The method returns the response from Gemini
        """
        # Get IDAAS token
        idaas_token = self.get_idaas_auth_token()
        logger.info("IDAAS Token generated {}".format(idaas_token))
        print("IDAAS Token generated {}".format(idaas_token))

        # Get GCP token
        gcp_token = self.get_gcp_token()
        logger.info("GCP Token generated {}".format(gcp_token))

        # Create headers with both tokens
        headers = {
            "x-gcp-authorization": f"Bearer {gcp_token}",
            "Authorization": f"Bearer {idaas_token}",
            "Content-Type": "application/json",
            "Accept": "application/json"
        }

        # Create LLM payload
        llm_payload = json.dumps({
            "contents": [
                {
                    "parts": [
                        {
                            "text": "Can you give me some info about Google LLM Gemini 1.5 Pro API details"
                        }
                    ],
                    "role": "model"
                }
            ]
        })

        logger.info("Payload: {}".format(llm_payload))

        # Call LLM - gemini pro
        try:
            query_response = requests.post(
                self.LLM_URL,
                headers=headers,
                data=llm_payload,
                verify=False
            )

            if query_response:
                logger.info("Query response in text format: {}".format(query_response.text))
                print(query_response.text)
                return json.loads(query_response.text)
            else:
                logger.info("Query response is None.")
                logger.info(query_response.content)
                return None

        except Exception as e:
            logger.error("Error: {}".format(e))
            return None

    def process_query(self, query: str) -> Dict:
        """
        Process user query through the complete pipeline
        """
        try:
            # 1. PII Scanning
            logger.info("Scanning for PII...")
            pii_findings = self.scan_pii(query)
            if any(findings for findings in pii_findings.values()):
                return {
                    "error": "PII detected in query",
                    "pii_findings": pii_findings
                }
            
            # 2. Generate Embeddings
            logger.info("Generating embeddings...")
            embeddings = self.get_embeddings(query)
            
            # 3. Semantic Search
            logger.info("Performing semantic search...")
            similar_docs = self.semantic_search(embeddings)
            
            # 4. Prepare Context
            context = "\n".join([doc["text"] for doc in similar_docs])
            
            # 5. Call LLM
            logger.info("Calling LLM...")
            response = self.call_llm(query, context)
            
            return {
                "query": query,
                "similar_documents": similar_docs,
                "response": response
            }
            
        except Exception as e:
            logger.error(f"Error processing query: {str(e)}")
            return {"error": str(e)}

def main():
    try:
        # Initialize controller
        controller = AIController()
        
        while True:
            # Get user input
            print("\nEnter your question (or 'quit' to exit):")
            query = input().strip()
            
            if query.lower() == 'quit':
                break
            
            # Process query
            print("\nProcessing your query...")
            result = controller.process_query(query)
            
            # Display results
            if "error" in result:
                print(f"\nError: {result['error']}")
                if "pii_findings" in result:
                    print("\nPII detected:")
                    for pii_type, findings in result["pii_findings"].items():
                        if findings:
                            print(f"{pii_type}: {len(findings)} instance(s)")
            else:
                print("\nRelevant documents found:")
                for doc in result["similar_documents"]:
                    print(f"- Similarity: {doc['similarity']:.2f}")
                    print(f"  Text: {doc['text'][:100]}...")
                
                print("\nResponse:")
                print(result["response"])
            
            print("\n" + "="*50)
            
    except KeyboardInterrupt:
        print("\nExiting...")
    except Exception as e:
        print(f"\nAn error occurred: {str(e)}")

if __name__ == "__main__":
    main()
