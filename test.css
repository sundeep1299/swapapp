import streamlit as st
import http.client
import json
from typing import Dict, Any

def call_llm_api(prompt: str) -> Dict[Any, Any]:
    """
    Call the LLM API with the given prompt
    """
    conn = http.client.HTTPConnection("10.50.66.58", 8081)
    
    payload = json.dumps({
        "model": "model1",
        "prompt": prompt,
        "max_tokens": 256,
        "min_tokens": 128
    })
    
    headers = {
        'Content-Type': 'application/json'
    }
    
    try:
        conn.request("POST", "/v1/completions", payload, headers)
        res = conn.getresponse()
        data = res.read()
        return json.loads(data.decode("utf-8"))
    except Exception as e:
        return {"error": str(e)}
    finally:
        conn.close()

def initialize_session_state():
    """Initialize session state variables"""
    if 'messages' not in st.session_state:
        st.session_state.messages = []

def main():
    st.set_page_config(
        page_title="LLM Chat Interface",
        page_icon="ðŸ’­",
        layout="wide"
    )

    initialize_session_state()

    # Application title
    st.title("ðŸ’­ LLM Chat Interface")

    # Chat messages container
    chat_container = st.container()

    # Display chat messages
    with chat_container:
        for message in st.session_state.messages:
            if message["role"] == "user":
                st.write(f"You: {message['content']}")
            elif message["role"] == "assistant":
                with st.expander("Assistant Response", expanded=True):
                    st.write(message["content"])
                    if "raw" in message:
                        with st.expander("Show raw response"):
                            st.json(message["raw"])
            elif message["role"] == "error":
                st.error(message["content"])

    # Input form
    with st.form(key="chat_form", clear_on_submit=True):
        col1, col2 = st.columns([6, 1])
        
        with col1:
            user_input = st.text_area(
                "Enter your message:",
                key="user_input",
                height=100
            )
        
        with col2:
            submit_button = st.form_submit_button("Send")

        if submit_button and user_input:
            # Add user message to chat
            st.session_state.messages.append({
                "role": "user",
                "content": user_input
            })

            # Show loading spinner while waiting for response
            with st.spinner("Generating response..."):
                try:
                    # Call LLM API
                    response = call_llm_api(user_input)
                    
                    if "error" in response:
                        st.session_state.messages.append({
                            "role": "error",
                            "content": f"Error: {response['error']}"
                        })
                    else:
                        # Add assistant response to chat
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": response["choices"][0]["text"],
                            "raw": response
                        })
                except Exception as e:
                    st.session_state.messages.append({
                        "role": "error",
                        "content": f"An error occurred: {str(e)}"
                    })

            # Rerun to update the UI
            st.experimental_rerun()

    # Add a clear chat button
    if st.button("Clear Chat"):
        st.session_state.messages = []
        st.experimental_rerun()

if __name__ == "__main__":
    main()