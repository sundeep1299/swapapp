import streamlit as st
import http.client
import json

def call_llm_api(prompt: str) -> dict:
    """
    Call the LLM API with the given prompt
    """
    # Create HTTP connection (not HTTPS)
    conn = http.client.HTTPConnection("10.50.66.58", 8081)
    
    payload = json.dumps({
        "model": "model1",
        "prompt": prompt,
        "max_tokens": 256,
        "min_tokens": 128
    })
    
    headers = {
        'Content-Type': 'application/json'
    }
    
    try:
        conn.request("POST", "/v1/completions", payload, headers)
        res = conn.getresponse()
        data = res.read()
        return json.loads(data.decode("utf-8"))
    except Exception as e:
        return {"error": str(e)}
    finally:
        conn.close()

def main():
    st.title("LLM Interface")
    
    # Text input for the prompt
    prompt = st.text_area("Enter your prompt:", height=100)
    
    # Submit button
    if st.button("Generate"):
        if prompt:
            with st.spinner("Generating response..."):
                response = call_llm_api(prompt)
                
                if "error" in response:
                    st.error(f"Error: {response['error']}")
                else:
                    st.success("Generation Complete!")
                    st.json(response)  # Display the full response

if __name__ == "__main__":
    main()