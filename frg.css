class LLMClient:
    def __init__(self, config: AuthConfig, token_manager: TokenManager):
        self.config = config
        self.token_manager = token_manager
        self.logger = Logger(__name__).logger

    async def generate_response(self, query: str) -> Dict[str, Any]:
        try:
            # Get both tokens using the generate_token method
            tokens = await self.token_manager.generate_token()
            
            headers = {
                "x-gcp-authorization": f"Bearer {tokens['gcp_token']}",
                "Authorization": f"Bearer {tokens['idaas_token']}",
                "Content-Type": "application/json",
                "Accept": "application/json"
            }

            payload = {
                "contents": [{
                    "parts": [{"text": query}],
                    "role": "model"
                }]
            }

            response = requests.post(
                self.config.llm_url,
                headers=headers,
                json=payload,
                verify=False
            )
            
            if response.ok:
                return response.json()
            else:
                raise LLMError(f"LLM request failed: {response.text}")
        except Exception as e:
            raise LLMError(f"Failed to generate LLM response: {str(e)}")
